import os
import requests
import json
import google.generativeai as genai
from datetime import datetime
import base64

# --- ç’°å¢ƒè®Šæ•¸è®€å– ---
GITHUB_TOKEN = os.environ['GITHUB_TOKEN']
REPO = os.environ['GITHUB_REPOSITORY']
PR_NUMBER = os.environ['PR_NUMBER']
GEMINI_API_KEY = os.environ['GEMINI_API_KEY']
GEMINI_MODEL = os.environ.get('GEMINI_MODEL', 'gemini-2.5-flash-lite-preview-06-17')

# --- API è¨­å®š ---
GITHUB_API_URL = "https://api.github.com"
GITHUB_HEADERS = {
    'Authorization': f'token {GITHUB_TOKEN}',
    'Accept': 'application/vnd.github.v3+json'
}

# è¨­å®š Gemini API é‡‘é‘°
genai.configure(api_key=GEMINI_API_KEY)


def get_pr_files():
    """ç²å– PR ä¸­æ‰€æœ‰è®Šæ›´çš„æ–‡ä»¶åˆ—è¡¨"""
    url = f"{GITHUB_API_URL}/repos/{REPO}/pulls/{PR_NUMBER}/files"
    response = requests.get(url, headers=GITHUB_HEADERS)
    response.raise_for_status()
    return response.json()


def get_pr_basic_info():
    """ç²å– PR åŸºæœ¬è³‡è¨Š"""
    pr_url = f"{GITHUB_API_URL}/repos/{REPO}/pulls/{PR_NUMBER}"
    pr_response = requests.get(pr_url, headers=GITHUB_HEADERS)
    pr_response.raise_for_status()
    return pr_response.json()


def get_enhanced_pr_diff():
    """å–å¾— Pull Request çš„å®Œæ•´ diff å…§å®¹ - å¢å¼·ç‰ˆï¼Œé¡¯ç¤ºæ›´å¤§ç¯„åœ"""
    try:
        pr_data = get_pr_basic_info()
        print(f"PR æ¨™é¡Œ: {pr_data.get('title', 'N/A')}")

        # æ–¹æ³•1: å˜—è©¦ç²å–å®Œæ•´çš„ unified diff æ ¼å¼
        print("ğŸ” å˜—è©¦ç²å–å®Œæ•´ unified diff...")
        diff_headers = GITHUB_HEADERS.copy()
        diff_headers['Accept'] = 'application/vnd.github.v3.diff'
        
        diff_url = f"{GITHUB_API_URL}/repos/{REPO}/pulls/{PR_NUMBER}"
        diff_response = requests.get(diff_url, headers=diff_headers)
        
        if diff_response.status_code == 200 and diff_response.text.strip():
            full_unified_diff = diff_response.text
            print(f"âœ… æˆåŠŸç²å–å®Œæ•´ unified diffï¼Œé•·åº¦: {len(full_unified_diff)}")
            
            # å¢åŠ æˆªæ–·é™åˆ¶åˆ° 100K
            if len(full_unified_diff) > 100000:
                print(f"âš ï¸  Diff å…§å®¹éé•·ï¼Œé€²è¡Œæˆªæ–·...")
                return full_unified_diff[:100000] + "\n\nâš ï¸ å…§å®¹å·²æˆªæ–·ï¼ˆunified diff æ ¼å¼ï¼‰"
            
            # æ·»åŠ  PR åŸºæœ¬è³‡è¨Šåˆ° diff é–‹é ­
            enhanced_diff = f"""Pull Request: {pr_data.get('title', '')}
URL: {pr_data.get('html_url', '')}
Author: {pr_data.get('user', {}).get('login', 'N/A')}
Base: {pr_data.get('base', {}).get('ref', 'N/A')} -> Head: {pr_data.get('head', {}).get('ref', 'N/A')}
Files changed: {pr_data.get('changed_files', 0)}
Additions: +{pr_data.get('additions', 0)} | Deletions: -{pr_data.get('deletions', 0)}

{'=' * 80}
UNIFIED DIFF CONTENT:
{'=' * 80}

{full_unified_diff}"""
            
            return enhanced_diff

        # æ–¹æ³•2: å¦‚æœ unified diff å¤±æ•—ï¼Œä½¿ç”¨å¢å¼·ç‰ˆçš„é€æ–‡ä»¶è™•ç†
        print("âš ï¸  Unified diff ç²å–å¤±æ•—ï¼Œä½¿ç”¨å¢å¼·ç‰ˆé€æ–‡ä»¶è™•ç†...")
        return get_enhanced_file_by_file_diff(pr_data)

    except Exception as e:
        print(f"âŒ ç²å–å¢å¼· PR diff æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        # é™ç´šåˆ°åŸå§‹æ–¹æ³•
        return get_pr_diff_fallback()


def get_enhanced_file_by_file_diff(pr_data):
    """å¢å¼·ç‰ˆçš„é€æ–‡ä»¶ diff è™•ç†ï¼ŒåŒ…å«æ›´å¤šä¸Šä¸‹æ–‡"""
    try:
        files = get_pr_files()
        print(f"å¯¦éš›ç²å–åˆ° {len(files)} å€‹è®Šæ›´æ–‡ä»¶")

        if not files:
            return "No files changed in this PR."

        full_diff = f"""Pull Request: {pr_data.get('title', '')}
URL: {pr_data.get('html_url', '')}
Author: {pr_data.get('user', {}).get('login', 'N/A')}
Base: {pr_data.get('base', {}).get('ref', 'N/A')} -> Head: {pr_data.get('head', {}).get('ref', 'N/A')}
Files changed: {len(files)}
Total additions: +{pr_data.get('additions', 0)} | Total deletions: -{pr_data.get('deletions', 0)}

{'=' * 80}
ENHANCED FILE-BY-FILE DIFF:
{'=' * 80}

"""

        for file_data in files:
            filename = file_data['filename']
            status = file_data['status']
            additions = file_data.get('additions', 0)
            deletions = file_data.get('deletions', 0)

            print(f"è™•ç†æ–‡ä»¶: {filename} (ç‹€æ…‹: {status}, +{additions}/-{deletions})")

            file_diff = f"\n{'=' * 60}\n"
            file_diff += f"ğŸ“ File: {filename}\n"
            file_diff += f"ğŸ“Š Status: {status}\n"
            file_diff += f"ğŸ“ˆ Changes: +{additions}/-{deletions}\n"
            
            if 'previous_filename' in file_data:
                file_diff += f"ğŸ“ Renamed from: {file_data['previous_filename']}\n"
            
            file_diff += f"{'=' * 60}\n"

            # æ·»åŠ æ¨™æº– patch
            if 'patch' in file_data and file_data['patch']:
                file_diff += "\n--- STANDARD PATCH ---\n"
                file_diff += file_data['patch']
                file_diff += "\n"

            # å°æ–¼å°çš„è®Šæ›´ï¼Œå˜—è©¦ç²å–æ›´å¤šä¸Šä¸‹æ–‡
            if additions + deletions <= 20 and status in ['modified', 'added']:
                print(f"  â””â”€ å˜—è©¦ç²å– {filename} çš„å®Œæ•´å…§å®¹ä¸Šä¸‹æ–‡...")
                file_context = get_file_full_context(filename, pr_data)
                if file_context:
                    file_diff += f"\n--- FULL FILE CONTEXT ---\n"
                    file_diff += f"Base SHA: {pr_data['base']['sha'][:8]}\n"
                    file_diff += f"Head SHA: {pr_data['head']['sha'][:8]}\n\n"
                    
                    if file_context.get('base_content'):
                        file_diff += f"--- BEFORE (Base) ---\n"
                        file_diff += file_context['base_content'][:5000]  # é™åˆ¶æ¯å€‹æ–‡ä»¶ 5K
                        if len(file_context['base_content']) > 5000:
                            file_diff += "\n... (truncated) ..."
                        file_diff += "\n\n"
                    
                    if file_context.get('head_content'):
                        file_diff += f"--- AFTER (Head) ---\n"
                        file_diff += file_context['head_content'][:5000]  # é™åˆ¶æ¯å€‹æ–‡ä»¶ 5K
                        if len(file_context['head_content']) > 5000:
                            file_diff += "\n... (truncated) ..."
                        file_diff += "\n"
            
            # å¦‚æœæ²’æœ‰ patch æ•¸æ“š
            if not file_data.get('patch'):
                file_diff += f"\nâš ï¸  No patch data available for {filename}"
                if status == 'added':
                    file_diff += " (æ–°å¢çš„æ–‡ä»¶)"
                elif status == 'removed':
                    file_diff += " (åˆªé™¤çš„æ–‡ä»¶)"
                elif status == 'renamed':
                    file_diff += " (é‡å‘½åçš„æ–‡ä»¶)"

            full_diff += file_diff + "\n"

        # å¢åŠ ç¸½é•·åº¦é™åˆ¶åˆ° 150K
        if len(full_diff) > 150000:
            print(f"âš ï¸  Enhanced diff å…§å®¹éé•·ï¼Œé€²è¡Œæˆªæ–·...")
            return full_diff[:150000] + "\n\nâš ï¸ å…§å®¹å·²æˆªæ–·ï¼ˆå¢å¼·ç‰ˆæ ¼å¼ï¼‰"

        return full_diff

    except Exception as e:
        print(f"âŒ ç²å–å¢å¼·æ–‡ä»¶ diff æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return get_pr_diff_fallback()


def get_file_full_context(filename, pr_data):
    """ç²å–æ–‡ä»¶åœ¨ PR å‰å¾Œçš„å®Œæ•´å…§å®¹"""
    try:
        base_content = None
        head_content = None
        
        # ç²å– base ç‰ˆæœ¬çš„æ–‡ä»¶å…§å®¹
        try:
            base_url = f"{GITHUB_API_URL}/repos/{REPO}/contents/{filename}"
            base_params = {'ref': pr_data['base']['sha']}
            base_response = requests.get(base_url, headers=GITHUB_HEADERS, params=base_params)
            
            if base_response.status_code == 200:
                base_content = base64.b64decode(base_response.json()['content']).decode('utf-8')
        except Exception:
            pass  # å¯èƒ½æ˜¯æ–°å¢çš„æ–‡ä»¶
        
        # ç²å– head ç‰ˆæœ¬çš„æ–‡ä»¶å…§å®¹
        try:
            head_url = f"{GITHUB_API_URL}/repos/{REPO}/contents/{filename}"
            head_params = {'ref': pr_data['head']['sha']}
            head_response = requests.get(head_url, headers=GITHUB_HEADERS, params=head_params)
            
            if head_response.status_code == 200:
                head_content = base64.b64decode(head_response.json()['content']).decode('utf-8')
        except Exception:
            pass  # å¯èƒ½æ˜¯åˆªé™¤çš„æ–‡ä»¶
        
        return {
            'base_content': base_content,
            'head_content': head_content
        }
        
    except Exception as e:
        print(f"    âŒ ç„¡æ³•ç²å– {filename} çš„å®Œæ•´å…§å®¹: {e}")
        return None


def get_pr_diff_fallback():
    """åŸå§‹ç‰ˆæœ¬çš„ diff ç²å–ä½œç‚ºå¾Œå‚™æ–¹æ¡ˆ"""
    try:
        pr_data = get_pr_basic_info()
        files = get_pr_files()
        
        if not files:
            return "No files changed in this PR."

        full_diff = f"Pull Request: {pr_data.get('title', '')}\n"
        full_diff += f"Files changed: {len(files)}\n\n"

        for file_data in files:
            filename = file_data['filename']
            status = file_data['status']
            additions = file_data.get('additions', 0)
            deletions = file_data.get('deletions', 0)

            file_diff = f"\n{'=' * 50}\n"
            file_diff += f"File: {filename}\n"
            file_diff += f"Status: {status}\n"
            file_diff += f"Changes: +{additions}/-{deletions}\n"
            file_diff += f"{'=' * 50}\n"

            if 'patch' in file_data and file_data['patch']:
                file_diff += file_data['patch']
            else:
                file_diff += f"(No patch data available for {filename})"

            full_diff += file_diff + "\n"

        # åŸå§‹çš„æˆªæ–·é™åˆ¶
        if len(full_diff) > 25000:
            print(f"âš ï¸  Fallback diff å…§å®¹éé•·ï¼Œé€²è¡Œæˆªæ–·...")
            return full_diff[:25000] + "\n\nâš ï¸ å…§å®¹å·²æˆªæ–·ï¼ˆfallback æ¨¡å¼ï¼‰"

        return full_diff

    except Exception as e:
        print(f"âŒ Fallback diff ç²å–å¤±æ•—: {e}")
        return f"Error fetching PR diff: {str(e)}"


def generate_json_with_gemini(diff_text):
    """éšæ®µ1: å°ˆé–€ç”¢ç”Ÿä¹¾æ·¨çš„ JSON æ ¼å¼"""
    if not diff_text.strip():
        return ""

    model = genai.GenerativeModel(GEMINI_MODEL)

    # éšæ®µ1: å°ˆæ³¨æ–¼ç”¢ç”Ÿæ ¼å¼æ­£ç¢ºçš„ JSON
    stage1_prompt = """
ä½ æ˜¯ä¸€å€‹ JSON ç”¢ç”Ÿå™¨ã€‚è«‹åˆ†æç¨‹å¼ç¢¼ diff ä¸¦ç”¢ç”Ÿæœ‰æ•ˆçš„ JSON é™£åˆ—ã€‚

é‡è¦è¦å‰‡ï¼š
1. åªå›å‚³ç´” JSON é™£åˆ—ï¼Œä¸è¦ä»»ä½•è§£é‡‹æ–‡å­—
2. ä¸è¦ä½¿ç”¨ ```json æˆ–ä»»ä½•åŒ…è£
3. ç‰¹æ®Šå­—ç¬¦å¿…é ˆæ­£ç¢ºè½‰ç¾©
4. æ¯å€‹ç‰©ä»¶å¿…é ˆåŒ…å«æ‰€æœ‰å¿…è¦æ¬„ä½

JSON çµæ§‹ï¼š
[
  {
    "file_path": "å­—ä¸²",
    "line_number": æ•¸å­—æˆ–null,
    "severity": "Critical/Warning/Info",
    "category": "å­—ä¸²",
    "title": "å­—ä¸²",
    "description": "å­—ä¸²",
    "suggestion": "å­—ä¸²",
    "fixed_code": "å­—ä¸²",
    "original_code": "å­—ä¸²"
  }
]

ç¯„ä¾‹ï¼ˆå¿…é ˆéµå¾ªæ­¤æ ¼å¼ï¼‰ï¼š
[{"file_path":"test.js","line_number":10,"severity":"Warning","category":"Code Quality","title":"å•é¡Œæ¨™é¡Œ","description":"å•é¡Œæè¿°","suggestion":"å»ºè­°ä¿®æ”¹","fixed_code":"ä¿®å¾©ç¨‹å¼ç¢¼","original_code":"åŸå§‹ç¨‹å¼ç¢¼"}]

åˆ†æä»¥ä¸‹ diff ä¸¦ç”¢ç”Ÿ JSONï¼š

__DIFF_PLACEHOLDER__
"""

    prompt = stage1_prompt.replace("__DIFF_PLACEHOLDER__", diff_text)

    try:
        print("ğŸ¯ éšæ®µ1: ç”¢ç”Ÿ JSON æ ¼å¼...")
        response = model.generate_content(prompt)

        if not response.text:
            return ""

        # æ¸…ç†å›æ‡‰
        cleaned_json = response.text.strip()
        cleaned_json = cleaned_json.replace('```json', '').replace('```', '').strip()
        
        # ç§»é™¤å¯èƒ½çš„å‰å¾Œæ–‡å­—ï¼Œåªä¿ç•™ JSON
        if cleaned_json.find('[') != -1 and cleaned_json.find(']') != -1:
            start_idx = cleaned_json.find('[')
            end_idx = cleaned_json.rfind(']') + 1
            cleaned_json = cleaned_json[start_idx:end_idx]

        print(f"âœ… JSON ç”¢ç”ŸæˆåŠŸï¼Œé•·åº¦: {len(cleaned_json)} å­—ç¬¦")
        return cleaned_json

    except Exception as e:
        print(f"âŒ éšæ®µ1 éŒ¯èª¤: {e}")
        return ""


def validate_and_enhance_json(json_text):
    """éšæ®µ2: é©—è­‰å’Œå„ªåŒ– JSON å…§å®¹"""
    if not json_text.strip():
        return []

    print("ğŸ” éšæ®µ2: é©—è­‰å’Œå„ªåŒ– JSON...")

    # å˜—è©¦è§£æ JSON
    try:
        data = json.loads(json_text)
        if not isinstance(data, list):
            print("âŒ JSON ä¸æ˜¯é™£åˆ—æ ¼å¼")
            return []
        
        print(f"âœ… JSON è§£ææˆåŠŸï¼ŒåŒ…å« {len(data)} å€‹é …ç›®")
        
    except json.JSONDecodeError as e:
        print(f"âŒ JSON æ ¼å¼éŒ¯èª¤: {e}")
        
        # å˜—è©¦ä¿®å¾© JSON
        try:
            print("ğŸ”§ å˜—è©¦ä¿®å¾© JSON...")
            import re
            
            # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå– JSON ç‰©ä»¶
            json_pattern = r'\{[^{}]*?"file_path"[^{}]*?\}'
            matches = re.findall(json_pattern, json_text, re.DOTALL)
            
            if matches:
                print(f"æ‰¾åˆ° {len(matches)} å€‹ JSON ç‰©ä»¶")
                valid_objects = []
                
                for i, match in enumerate(matches):
                    try:
                        # æ¸…ç†å’Œä¿®å¾©å–®å€‹ç‰©ä»¶
                        cleaned_match = match.strip()
                        obj = json.loads(cleaned_match)
                        valid_objects.append(obj)
                        print(f"  âœ… ç‰©ä»¶ {i+1} è§£ææˆåŠŸ")
                    except Exception as obj_error:
                        print(f"  âŒ ç‰©ä»¶ {i+1} è§£æå¤±æ•—: {obj_error}")
                        continue
                
                if valid_objects:
                    data = valid_objects
                    print(f"âœ… ä¿®å¾©æˆåŠŸï¼ç²å¾— {len(data)} å€‹æœ‰æ•ˆç‰©ä»¶")
                else:
                    print("âŒ æ²’æœ‰æœ‰æ•ˆçš„ JSON ç‰©ä»¶")
                    return []
            else:
                print("âŒ æ‰¾ä¸åˆ°æœ‰æ•ˆçš„ JSON ç‰©ä»¶")
                return []
                
        except Exception as fix_error:
            print(f"âŒ JSON ä¿®å¾©å¤±æ•—: {fix_error}")
            return []

    # é©—è­‰å’Œå„ªåŒ–æ¯å€‹é …ç›®çš„å…§å®¹
    validated_items = []
    required_fields = ['file_path', 'severity', 'category', 'title', 'description', 'suggestion']
    
    for i, item in enumerate(data):
        if not isinstance(item, dict):
            print(f"âš ï¸  é …ç›® {i+1} ä¸æ˜¯ç‰©ä»¶æ ¼å¼ï¼Œè·³é")
            continue
        
        # æª¢æŸ¥å¿…è¦æ¬„ä½
        missing_fields = [field for field in required_fields if field not in item]
        if missing_fields:
            print(f"âš ï¸  é …ç›® {i+1} ç¼ºå°‘æ¬„ä½: {missing_fields}ï¼Œå˜—è©¦è£œå……...")
            
            # è£œå……ç¼ºå°‘çš„æ¬„ä½
            for field in missing_fields:
                if field == 'severity':
                    item[field] = 'Info'
                elif field == 'category':
                    item[field] = 'Code Quality'
                else:
                    item[field] = f'æœªæä¾›{field}'
        
        # é©—è­‰åš´é‡ç¨‹åº¦
        if item.get('severity') not in ['Critical', 'Warning', 'Info']:
            print(f"âš ï¸  é …ç›® {i+1} åš´é‡ç¨‹åº¦ç„¡æ•ˆï¼Œè¨­ç‚º Info")
            item['severity'] = 'Info'
        
        # ç¢ºä¿æ•¸å­—æ¬„ä½æ­£ç¢º
        if 'line_number' in item and item['line_number'] is not None:
            try:
                item['line_number'] = int(item['line_number'])
            except (ValueError, TypeError):
                item['line_number'] = None
        
        # ç¢ºä¿å­—ä¸²æ¬„ä½ä¸ç‚ºç©º
        for field in ['title', 'description', 'suggestion']:
            if not item.get(field) or not isinstance(item[field], str):
                item[field] = f'æœªæä¾›{field}'
        
        # ç¢ºä¿ç¨‹å¼ç¢¼æ¬„ä½å­˜åœ¨
        if 'fixed_code' not in item:
            item['fixed_code'] = ''
        if 'original_code' not in item:
            item['original_code'] = ''
        
        validated_items.append(item)
        print(f"  âœ… é …ç›® {i+1}: {item.get('title', 'N/A')} ({item.get('severity', 'N/A')})")

    print(f"ğŸ‰ éšæ®µ2 å®Œæˆï¼é©—è­‰äº† {len(validated_items)} å€‹æœ‰æ•ˆé …ç›®")
    return validated_items


def analyze_diff_with_gemini(diff_text):
    """ä½¿ç”¨ 2 éšæ®µæ–¹æ³•åˆ†æ diff"""
    print("ğŸš€ å•Ÿå‹• 2 éšæ®µ AI åˆ†æ...")
    
    # éšæ®µ1: ç”¢ç”Ÿ JSON
    json_text = generate_json_with_gemini(diff_text)
    if not json_text:
        print("âŒ éšæ®µ1 å¤±æ•—ï¼Œç„¡æ³•ç”¢ç”Ÿ JSON")
        return []
    
    # éšæ®µ2: é©—è­‰å’Œå„ªåŒ–
    validated_results = validate_and_enhance_json(json_text)
    
    if validated_results:
        print(f"âœ… 2 éšæ®µåˆ†æå®Œæˆï¼æœ€çµ‚ç²å¾— {len(validated_results)} å€‹åˆ†æè¦é»")
    else:
        print("âŒ 2 éšæ®µåˆ†æå¤±æ•—ï¼Œç„¡æœ‰æ•ˆçµæœ")
    
    return validated_results


def create_github_style_comment(analysis_data):
    """å‰µå»ºé¡ä¼¼GitHubåŸç”Ÿé«”é©—çš„ç•™è¨€"""

    file_path = analysis_data.get('file_path', 'N/A')
    line_number = analysis_data.get('line_number', '')
    severity = analysis_data.get('severity', 'Info')
    category = analysis_data.get('category', 'Code Quality')
    title = analysis_data.get('title', 'ç¨‹å¼ç¢¼å»ºè­°')
    description = analysis_data.get('description', '')
    suggestion = analysis_data.get('suggestion', '')
    fixed_code = analysis_data.get('fixed_code', '')
    original_code = analysis_data.get('original_code', '')

    # åš´é‡ç¨‹åº¦æ¨£å¼
    severity_config = {
        'Critical': ('#d1242f', 'ğŸ”´', 'Critical'),
        'Warning': ('#bf8700', 'ğŸŸ¡', 'Warning'),
        'Info': ('#0969da', 'ğŸ”µ', 'Info')
    }

    color, emoji, label = severity_config.get(severity, ('#0969da', 'ğŸ”µ', 'Info'))

    # é¡åˆ¥åœ–ç¤º
    category_icons = {
        'Security': 'ğŸ”’', 'Performance': 'âš¡', 'Code Quality': 'âœ¨',
        'Bug Risk': 'ğŸ›', 'Maintainability': 'ğŸ”§', 'Best Practice': 'ğŸ’¡'
    }

    category_icon = category_icons.get(category, 'ğŸ“‹')

    # æ§‹å»ºç•™è¨€å…§å®¹
    body = f"""## {emoji} {title}

<table style="width: 100%; border: none; margin-bottom: 16px;">
<tr>
<td style="background-color: {color}; color: white; padding: 6px 12px; border-radius: 6px; font-weight: bold; white-space: nowrap; border: none;">
{label}
</td>
<td style="padding: 6px 12px; border: none;">
{category_icon} <strong>{category}</strong>
</td>
<td style="padding: 6px 12px; text-align: right; border: none;">
ğŸ“ <code>{file_path}</code>{f' :line_number: {line_number}' if line_number else ''}
</td>
</tr>
</table>

### ğŸ” å•é¡Œèªªæ˜
{description}

### ğŸ’¡ å»ºè­°ä¿®æ”¹
{suggestion}"""

    # æ·»åŠ ç¨‹å¼ç¢¼å°æ¯”
    if original_code and fixed_code:
        body += f"""

### ğŸ“‹ ç¨‹å¼ç¢¼ä¿®æ”¹å»ºè­°

<table style="width: 100%; border-collapse: collapse; border: 1px solid #d0d7de; border-radius: 6px; overflow: hidden; margin: 16px 0;">
<thead>
<tr style="background-color: #f6f8fa;">
<th style="padding: 8px 12px; text-align: left; border-bottom: 1px solid #d0d7de; width: 50%;">âŒ ä¿®æ”¹å‰</th>
<th style="padding: 8px 12px; text-align: left; border-bottom: 1px solid #d0d7de; width: 50%;">âœ… ä¿®æ”¹å¾Œ</th>
</tr>
</thead>
<tbody>
<tr>
<td style="padding: 12px; border-right: 1px solid #d0d7de; background-color: #ffebe9; vertical-align: top;">

```javascript
{original_code}
```

</td>
<td style="padding: 12px; background-color: #dafbe1; vertical-align: top;">

```javascript
{fixed_code}
```

</td>
</tr>
</tbody>
</table>"""

    elif original_code or fixed_code:
        # å¦‚æœåªæœ‰å…¶ä¸­ä¸€å€‹
        code_to_show = fixed_code if fixed_code else original_code
        code_label = "å»ºè­°ç¨‹å¼ç¢¼" if fixed_code else "ç›¸é—œç¨‹å¼ç¢¼"

        body += f"""

### ğŸ“ {code_label}

```javascript
{code_to_show}
```"""

    # æ·»åŠ åº•éƒ¨æ¨™ç±¤
    body += f"""

---

<sub>ğŸ¤– <em>ç”± AI ç¨‹å¼ç¢¼å¯©æŸ¥åŠ©æ‰‹è‡ªå‹•ç”Ÿæˆ (Enhanced Version)</em> | {category_icon} <em>{category}</em> | ğŸ“… <em>{datetime.now().strftime("%Y-%m-%d %H:%M")}</em></sub>"""

    return body


def create_summary_comment(analysis_results):
    """å‰µå»ºæ‘˜è¦ç•™è¨€"""

    if not analysis_results:
        return None

    # çµ±è¨ˆåˆ†æ
    critical_count = sum(1 for item in analysis_results if item.get('severity') == 'Critical')
    warning_count = sum(1 for item in analysis_results if item.get('severity') == 'Warning')
    info_count = sum(1 for item in analysis_results if item.get('severity') == 'Info')

    # æŒ‰é¡åˆ¥çµ±è¨ˆ
    categories = {}
    for item in analysis_results:
        cat = item.get('category', 'Other')
        categories[cat] = categories.get(cat, 0) + 1

    body = f"""## ğŸ¤– AI ç¨‹å¼ç¢¼å¯©æŸ¥æ‘˜è¦å ±å‘Š (Enhanced)

### ğŸ“Š ç¸½é«”çµ±è¨ˆ

<table style="width: 100%; border-collapse: collapse; border: 1px solid #d0d7de; border-radius: 6px; overflow: hidden;">
<thead>
<tr style="background-color: #f6f8fa;">
<th style="padding: 12px; text-align: center; border-bottom: 1px solid #d0d7de;">ğŸ”´ Critical</th>
<th style="padding: 12px; text-align: center; border-bottom: 1px solid #d0d7de;">ğŸŸ¡ Warning</th>
<th style="padding: 12px; text-align: center; border-bottom: 1px solid #d0d7de;">ğŸ”µ Info</th>
<th style="padding: 12px; text-align: center; border-bottom: 1px solid #d0d7de;">ğŸ“‹ ç¸½è¨ˆ</th>
</tr>
</thead>
<tbody>
<tr>
<td style="padding: 12px; text-align: center; background-color: {('#ffebe9' if critical_count > 0 else '#f6f8fa')};">
<strong style="color: #d1242f;">{critical_count}</strong>
</td>
<td style="padding: 12px; text-align: center; background-color: {('#fff3cd' if warning_count > 0 else '#f6f8fa')};">
<strong style="color: #bf8700;">{warning_count}</strong>
</td>
<td style="padding: 12px; text-align: center; background-color: {('#e7f3ff' if info_count > 0 else '#f6f8fa')};">
<strong style="color: #0969da;">{info_count}</strong>
</td>
<td style="padding: 12px; text-align: center;">
<strong>{len(analysis_results)}</strong>
</td>
</tr>
</tbody>
</table>

### ğŸ·ï¸ å•é¡Œåˆ†é¡"""

    # æ·»åŠ åˆ†é¡çµ±è¨ˆ
    for category, count in categories.items():
        category_icon = {
            'Security': 'ğŸ”’', 'Performance': 'âš¡', 'Code Quality': 'âœ¨',
            'Bug Risk': 'ğŸ›', 'Maintainability': 'ğŸ”§', 'Best Practice': 'ğŸ’¡'
        }.get(category, 'ğŸ“‹')

        body += f"""
- {category_icon} **{category}**: {count} å€‹å•é¡Œ"""

    # æ·»åŠ å¿«é€Ÿå°èˆª
    body += f"""

### ğŸ” è©³ç´°å•é¡Œåˆ—è¡¨"""

    for i, item in enumerate(analysis_results, 1):
        severity_emoji = {'Critical': 'ğŸ”´', 'Warning': 'ğŸŸ¡', 'Info': 'ğŸ”µ'}.get(item.get('severity'), 'ğŸ”µ')
        category_icon = {
            'Security': 'ğŸ”’', 'Performance': 'âš¡', 'Code Quality': 'âœ¨',
            'Bug Risk': 'ğŸ›', 'Maintainability': 'ğŸ”§', 'Best Practice': 'ğŸ’¡'
        }.get(item.get('category'), 'ğŸ“‹')

        body += f"""
{i}. {severity_emoji} **{item.get('title', 'N/A')}** {category_icon}  
   ğŸ“ `{item.get('file_path', 'N/A')}`{f" :line_number: {item.get('line_number')}" if item.get('line_number') else ""}"""

    body += f"""

---

<sub>ğŸ¤– <em>å¢å¼·ç‰ˆç¨‹å¼ç¢¼å¯©æŸ¥åŠ©æ‰‹ - æä¾›æ›´æ·±å…¥çš„ä»£ç¢¼åˆ†æ</em> | ğŸ“… <em>{datetime.now().strftime("%Y-%m-%d %H:%M")}</em></sub>"""

    return body


def post_comment(body):
    """ç™¼ä½ˆç•™è¨€åˆ° PR"""
    url = f"{GITHUB_API_URL}/repos/{REPO}/issues/{PR_NUMBER}/comments"
    response = requests.post(url, json={'body': body}, headers=GITHUB_HEADERS)

    try:
        response.raise_for_status()
        return True
    except Exception as e:
        print(f"âŒ ç™¼ä½ˆç•™è¨€å¤±æ•—: {e}")
        return False


def post_review_comment(file_path, line_number, body):
    """ç™¼ä½ˆç¨‹å¼ç¢¼è¡Œç´šåˆ¥çš„å¯©æŸ¥ç•™è¨€ï¼ˆå¦‚æœå¯èƒ½çš„è©±ï¼‰"""

    # å˜—è©¦ç™¼ä½ˆ review commentï¼ˆè¡Œç´šåˆ¥ï¼‰
    try:
        pr_data = get_pr_basic_info()
        sha = pr_data['head']['sha']

        review_payload = {
            "body": "AI ç¨‹å¼ç¢¼å¯©æŸ¥ (Enhanced)",
            "event": "COMMENT",
            "comments": [
                {
                    "path": file_path,
                    "line": line_number,
                    "body": body
                }
            ]
        }

        review_url = f"{GITHUB_API_URL}/repos/{REPO}/pulls/{PR_NUMBER}/reviews"
        review_response = requests.post(review_url, json=review_payload, headers=GITHUB_HEADERS)

        if review_response.status_code == 200:
            print(f"âœ… æˆåŠŸç™¼ä½ˆè¡Œç´šåˆ¥ç•™è¨€: {file_path}:{line_number}")
            return True
        else:
            print(f"âš ï¸  è¡Œç´šåˆ¥ç•™è¨€å¤±æ•—ï¼Œæ”¹ç”¨ä¸€èˆ¬ç•™è¨€")
            return False

    except Exception as e:
        print(f"âš ï¸  ç„¡æ³•ç™¼ä½ˆè¡Œç´šåˆ¥ç•™è¨€: {e}")
        return False


if __name__ == "__main__":
    try:
        print("ğŸš€ é–‹å§‹é€²è¡Œå¢å¼·ç‰ˆ GitHub ç¨‹å¼ç¢¼å¯©æŸ¥...")
        print("=" * 70)

        # ç²å–å¢å¼·ç‰ˆ diff å’Œåˆ†æ
        print("ğŸ“¥ ç²å– PR diff å…§å®¹...")
        diff = get_enhanced_pr_diff()
        
        print(f"ğŸ“„ Diff å…§å®¹é•·åº¦: {len(diff)} å­—ç¬¦")
        print("ğŸ¤– é–‹å§‹ AI åˆ†æ...")
        
        analysis_results = analyze_diff_with_gemini(diff)

        if analysis_results:
            print(f"âœ… åˆ†æå®Œæˆï¼ç™¼ç¾ {len(analysis_results)} å€‹å•é¡Œ")

            # å…ˆç™¼ä½ˆæ‘˜è¦ç•™è¨€
            summary_body = create_summary_comment(analysis_results)
            if summary_body:
                if post_comment(summary_body):
                    print("âœ… å¢å¼·ç‰ˆæ‘˜è¦å ±å‘Šå·²ç™¼ä½ˆ")
                else:
                    print("âŒ æ‘˜è¦å ±å‘Šç™¼ä½ˆå¤±æ•—")

            # ç™¼ä½ˆæ¯å€‹è©³ç´°å•é¡Œ
            success_count = 0
            for i, analysis in enumerate(analysis_results, 1):
                print(f"\nğŸ“ ç™¼ä½ˆç¬¬ {i} å€‹å•é¡Œ: {analysis.get('title', 'N/A')}")

                comment_body = create_github_style_comment(analysis)

                # å˜—è©¦è¡Œç´šåˆ¥ç•™è¨€ï¼Œå¤±æ•—å‰‡ç”¨ä¸€èˆ¬ç•™è¨€
                line_num = analysis.get('line_number')
                file_path = analysis.get('file_path')

                if line_num and file_path:
                    if not post_review_comment(file_path, line_num, comment_body):
                        # è¡Œç´šåˆ¥å¤±æ•—ï¼Œä½¿ç”¨ä¸€èˆ¬ç•™è¨€
                        if post_comment(comment_body):
                            success_count += 1
                    else:
                        success_count += 1
                else:
                    # æ²’æœ‰è¡Œè™Ÿï¼Œç›´æ¥ç”¨ä¸€èˆ¬ç•™è¨€
                    if post_comment(comment_body):
                        success_count += 1

            print("\n" + "=" * 70)
            print(f"ğŸ‰ å¢å¼·ç‰ˆ GitHub ç¨‹å¼ç¢¼å¯©æŸ¥å®Œæˆï¼")
            print(f"ğŸ“Š æˆåŠŸç™¼ä½ˆ {success_count}/{len(analysis_results)} å€‹å•é¡Œ")
            print(f"ğŸ” ä½¿ç”¨äº†å¢å¼·ç‰ˆ diff åˆ†æï¼Œæä¾›æ›´æ·±å…¥çš„ç¨‹å¼ç¢¼å¯©æŸ¥")
        else:
            # å³ä½¿æ²’æœ‰å•é¡Œï¼Œä¹Ÿç™¼ä½ˆä¸€å€‹ç°¡çŸ­çš„å ±å‘Š
            no_issues_body = f"""## ğŸ¤– AI ç¨‹å¼ç¢¼å¯©æŸ¥å ±å‘Š (Enhanced)

### âœ… å¯©æŸ¥çµæœ

æ­å–œï¼æœ¬æ¬¡ Pull Request æ²’æœ‰ç™¼ç¾æ˜é¡¯çš„ç¨‹å¼ç¢¼å•é¡Œã€‚

### ğŸ“Š å¯©æŸ¥ç¯„åœ
- ä½¿ç”¨äº†å¢å¼·ç‰ˆ diff åˆ†æ
- åŒ…å«æ›´å®Œæ•´çš„ç¨‹å¼ç¢¼ä¸Šä¸‹æ–‡
- æ·±åº¦æª¢æŸ¥å®‰å…¨æ€§ã€æ•ˆèƒ½å’Œç¨‹å¼ç¢¼å“è³ª

---

<sub>ğŸ¤– <em>å¢å¼·ç‰ˆç¨‹å¼ç¢¼å¯©æŸ¥åŠ©æ‰‹</em> | ğŸ“… <em>{datetime.now().strftime("%Y-%m-%d %H:%M")}</em></sub>"""
            
            if post_comment(no_issues_body):
                print("âœ… æœªç™¼ç¾å•é¡Œï¼Œå·²ç™¼ä½ˆç¢ºèªå ±å‘Š")
            else:
                print("â„¹ï¸  æ²’æœ‰ç™¼ç¾éœ€è¦å¯©æŸ¥çš„å•é¡Œ")

    except Exception as e:
        print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
